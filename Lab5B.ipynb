{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9571f04e",
   "metadata": {},
   "source": [
    "# Lab5 B: Generate your QNN to hardware (optional)\n",
    "note: This part can only be executed in the docker mentioned in Lab5 A, hence it is a optional part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d76cf",
   "metadata": {},
   "source": [
    "In Lab5 A, we trained a quantised network, and in this lab we will compile it to a hardware format to deploy it on our FPGAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be613b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "#\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "import shutil\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "#\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03afe257",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"lab_new/exports/kws_mlp_w3a3_qonnx.onnx\"\n",
    "estimates_output_dir = \"output/google_speech/output_estimates_only\"\n",
    "final_output_dir = \"output/google_speech/output_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b77dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from lab_new/exports/kws_mlp_w3a3_qonnx.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_changhong\n",
      "Final outputs will be generated in output/google_speech/output_estimates_only\n",
      "Build log is at output/google_speech/output_estimates_only/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/10]\n",
      "Running step: step_tidy_up [2/10]\n",
      "Running step: step_streamline [3/10]\n",
      "Running step: step_convert_to_hw [4/10]\n",
      "Running step: step_create_dataflow_partition [5/10]\n",
      "Running step: step_specialize_layers [6/10]\n",
      "Running step: step_target_fps_parallelization [7/10]\n",
      "Running step: step_apply_folding_config [8/10]\n",
      "Running step: step_minimize_bit_width [9/10]\n",
      "Running step: step_generate_estimate_reports [10/10]\n",
      "Completed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 ,100000, 160000\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 160000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8892cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_deployment = build.DataflowBuildConfig(\n",
    "    output_dir          = final_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    board               = \"Pynq-Z2\",\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")\n",
    "# build.build_dataflow_cfg(model_file, cfg_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf27a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 bit, target fps 1000\n",
      "starting time: 2025-11-07 03:00:52.723140\n",
      "Building dataflow accelerator from lab_new/exports/kws_mlp_w3a3_qonnx.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_changhong\n",
      "Final outputs will be generated in output/google_speech/b3_f1k\n",
      "Build log is at output/google_speech/b3_f1k/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/19]\n",
      "Running step: step_tidy_up [2/19]\n",
      "Running step: step_streamline [3/19]\n",
      "Running step: step_convert_to_hw [4/19]\n",
      "Running step: step_create_dataflow_partition [5/19]\n",
      "Running step: step_specialize_layers [6/19]\n",
      "Running step: step_target_fps_parallelization [7/19]\n",
      "Running step: step_apply_folding_config [8/19]\n",
      "Running step: step_minimize_bit_width [9/19]\n",
      "Running step: step_generate_estimate_reports [10/19]\n",
      "Running step: step_hw_codegen [11/19]\n",
      "Running step: step_hw_ipgen [12/19]\n",
      "Running step: step_set_fifo_depths [13/19]\n",
      "Running step: step_create_stitched_ip [14/19]\n",
      "Running step: step_measure_rtlsim_performance [15/19]\n",
      "> \u001b[0;32m/home/changhong/prj/finn_cli_fork/src/finn/builder/build_dataflow_steps.py\u001b[0m(687)\u001b[0;36mstep_measure_rtlsim_performance\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    685 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mDataflowOutputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLSIM_PERFORMANCE\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    686 \u001b[0;31m        assert (\n",
      "\u001b[0m\u001b[0;32m--> 687 \u001b[0;31m            \u001b[0mDataflowOutputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTITCHED_IP\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    688 \u001b[0;31m        ), \"rtlsim_perf needs stitched IP\"\n",
      "\u001b[0m\u001b[0;32m    689 \u001b[0;31m        \u001b[0mreport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/report\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/builder/build_dataflow.py\", line 158, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/builder/build_dataflow_steps.py\", line 687, in step_measure_rtlsim_performance\n",
      "    DataflowOutputType.STITCHED_IP in cfg.generate_outputs\n",
      "AssertionError: rtlsim_perf needs stitched IP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "Build failed\n",
      "finished time: 1762484683.5175462, total time: 230.7944130897522 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1000 ,100000, 160000\n",
    "import time\n",
    "import datetime\n",
    "c_time = time.time()\n",
    "print(\"3 bit, target fps 1000\")\n",
    "print(f\"starting time: {datetime.datetime.fromtimestamp(c_time)}\")\n",
    "model_file = \"lab_new/exports/kws_mlp_w3a3_qonnx.onnx\"\n",
    "final_output_dir = \"output/google_speech/b3_f1k\"\n",
    "target_fps = 1000\n",
    "cfg_deployment = build.DataflowBuildConfig(\n",
    "    output_dir          = final_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = target_fps,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    board               = \"Pynq-Z2\",\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")\n",
    "build.build_dataflow_cfg(model_file, cfg_deployment)\n",
    "print(f\"finished time: {time.time()}, total time: {time.time() - c_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7483d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_time = time.time()\n",
    "print(\"3 bit, target fps 100000\")\n",
    "model_file = \"lab_new/exports/kws_mlp_w3a3_qonnx.onnx\"\n",
    "final_output_dir = \"output/google_speech/b3_f100k\"\n",
    "target_fps = 100000\n",
    "cfg_deployment = build.DataflowBuildConfig(\n",
    "    output_dir          = final_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = target_fps,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    board               = \"Pynq-Z2\",\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")\n",
    "build.build_dataflow_cfg(model_file, cfg_deployment)\n",
    "print(f\"finished time: {time.time()}, total time: {time.time() - c_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_time = time.time()\n",
    "print(\"3 bit, target fps 160000\")\n",
    "model_file = \"lab_new/exports/kws_mlp_w3a3_qonnx.onnx\"\n",
    "final_output_dir = \"output/google_speech/b3_f160k\"\n",
    "target_fps = 160000\n",
    "cfg_deployment = build.DataflowBuildConfig(\n",
    "    output_dir          = final_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = target_fps,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    board               = \"Pynq-Z2\",\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")\n",
    "build.build_dataflow_cfg(model_file, cfg_deployment)\n",
    "print(f\"finished time: {time.time()}, total time: {time.time() - c_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd5be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting time: 1762483473.1268692\n",
      "3 bit, target fps 1000\n",
      "Building dataflow accelerator from lab_new/exports/kws_mlp_w3a3_qonnx.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_changhong\n",
      "Final outputs will be generated in output/google_speech/b3_f1k\n",
      "Build log is at output/google_speech/b3_f1k/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/19]\n",
      "Running step: step_tidy_up [2/19]\n",
      "Running step: step_streamline [3/19]\n",
      "Running step: step_convert_to_hw [4/19]\n",
      "Running step: step_create_dataflow_partition [5/19]\n",
      "Running step: step_specialize_layers [6/19]\n",
      "Running step: step_target_fps_parallelization [7/19]\n",
      "Running step: step_apply_folding_config [8/19]\n",
      "Running step: step_minimize_bit_width [9/19]\n",
      "Running step: step_generate_estimate_reports [10/19]\n",
      "Running step: step_hw_codegen [11/19]\n",
      "Running step: step_hw_ipgen [12/19]\n",
      "Running step: step_set_fifo_depths [13/19]\n",
      "Running step: step_create_stitched_ip [14/19]\n",
      "Running step: step_measure_rtlsim_performance [15/19]\n",
      "Running step: step_out_of_context_synthesis [16/19]\n",
      "Running step: step_synthesize_bitfile [17/19]\n",
      "> \u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m(1141)\u001b[0;36mcommunicate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1139 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1140 \u001b[0;31m            \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1141 \u001b[0;31m                \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1142 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1143 \u001b[0;31m            \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/builder/build_dataflow.py\", line 158, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/builder/build_dataflow_steps.py\", line 808, in step_synthesize_bitfile\n",
      "    model = model.transform(\n",
      "  File \"/home/changhong/prj/finn_cli_fork/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 145, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/transformation/fpgadataflow/make_zynq_proj.py\", line 347, in apply\n",
      "    model = model.transform(\n",
      "  File \"/home/changhong/prj/finn_cli_fork/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 145, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/transformation/fpgadataflow/make_zynq_proj.py\", line 261, in apply\n",
      "    process_compile.communicate()\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 1141, in communicate\n",
      "    stdout = self.stdout.read()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build failed\n",
      "finished time: 1762483945.486747, total time: 472.3598835468292 seconds\n",
      "3 bit, target fps 100000\n",
      "Building dataflow accelerator from lab_new/exports/kws_mlp_w3a3_qonnx.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_changhong\n",
      "Final outputs will be generated in output/google_speech/b3_f100k\n",
      "Build log is at output/google_speech/b3_f100k/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/19]\n",
      "Running step: step_tidy_up [2/19]\n",
      "Running step: step_streamline [3/19]\n",
      "Running step: step_convert_to_hw [4/19]\n",
      "Running step: step_create_dataflow_partition [5/19]\n",
      "Running step: step_specialize_layers [6/19]\n",
      "Running step: step_target_fps_parallelization [7/19]\n",
      "Running step: step_apply_folding_config [8/19]\n",
      "Running step: step_minimize_bit_width [9/19]\n",
      "Running step: step_generate_estimate_reports [10/19]\n",
      "Running step: step_hw_codegen [11/19]\n",
      "Running step: step_hw_ipgen [12/19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m(320)\u001b[0;36mwait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    318 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    319 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 320 \u001b[0;31m                \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    321 \u001b[0;31m                \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    322 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/builder/build_dataflow.py\", line 158, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/home/changhong/prj/finn_cli_fork/src/finn/builder/build_dataflow_steps.py\", line 522, in step_hw_ipgen\n",
      "    model = model.transform(HLSSynthIP())\n",
      "  File \"/home/changhong/prj/finn_cli_fork/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 145, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/changhong/prj/finn_cli_fork/deps/qonnx/src/qonnx/transformation/base.py\", line 112, in apply\n",
      "    new_nodes_and_bool = p.map(self.applyNodeLocal, old_nodes, chunksize=1)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 367, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 768, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 765, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "c_time = time.time()\n",
    "print(\"4 bit, target fps 100000\")\n",
    "model_file = \"lab_new/exports/kws_mlp_w4a4_qonnx.onnx\"\n",
    "final_output_dir = \"output/google_speech/b4_f100k\"\n",
    "target_fps = 100000\n",
    "cfg_deployment = build.DataflowBuildConfig(\n",
    "    output_dir          = final_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = target_fps,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    board               = \"Pynq-Z2\",\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")\n",
    "build.build_dataflow_cfg(model_file, cfg_deployment)\n",
    "print(f\"finished time: {time.time()}, total time: {time.time() - c_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf73d3",
   "metadata": {},
   "source": [
    "## Try other parameters and answer (optional):\n",
    "- Q1: What performance can you obtain from the estimation report and final generation report?\n",
    "- Q2: Explain what happened to each intermediate model / step.\n",
    "- Q3: Try different setup with estimation code, if you change target_fps, what will happen?\n",
    "- Q4: What is the performance bottleneck and pipeline balance in a dataflow model?\n",
    "- Q5: Explain SIMD and PE.\n",
    "- Q6: What is the best performance you could reach with PYNQ-Z2 board?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")\n",
    "# build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
